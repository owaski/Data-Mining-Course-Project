{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('graph': conda)",
   "metadata": {
    "interpreter": {
     "hash": "01386749bdee9de7e3f30e96cd17530d8e592ff893fafeeaedbf0286ef117601"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from utils import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../dataset/b/cache.pt'\n",
    "model_dir = '../models/tuned_b'\n",
    "model_path = os.path.join(model_dir, 'model.pt')\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, features, edge_index, edge_attr, labels, train_mask, eval_mask, test_mask = torch.load(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=features, edge_index=edge_index, edge_attr=edge_attr, y=labels, train_mask=train_mask, test_mask=test_mask, eval_mask=eval_mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.4068, -2.2860, -1.9563, -0.5715, -3.2606, -2.7521],\n",
       "        [-3.7088, -0.1774, -2.8229, -3.8807, -3.4557, -3.6327],\n",
       "        [-3.1680, -3.5078, -3.5060, -3.0157, -2.8196, -0.2366],\n",
       "        ...,\n",
       "        [-3.2262, -2.1226, -1.0199, -0.8682, -3.5160, -3.4889],\n",
       "        [-2.1501, -0.6912, -3.2305, -2.8570, -1.7174, -2.2439],\n",
       "        [-2.5790, -1.4328, -2.8318, -3.1127, -2.7010, -0.6636]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = probs.argmax(dim=-1).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "class 0 : total 249 recall 0.3534136414527893\nclass 1 : total 590 recall 0.7966101765632629\nclass 2 : total 668 recall 0.8218562602996826\nclass 3 : total 701 recall 0.8502140045166016\nclass 4 : total 596 recall 0.8808724880218506\nclass 5 : total 523 recall 0.7801147103309631\n"
     ]
    }
   ],
   "source": [
    "for i in range(config['n_class']):\n",
    "    n_correct = (pred_labels == labels).logical_and(labels == i).sum()\n",
    "    n_total = (labels == i).sum()\n",
    "    print('class {} : total {} recall {}'.format(i, n_total.item(), (n_correct / n_total).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_features = [[] for i in range(config['n_class'])]\n",
    "for i in range(config['n_vertex']):\n",
    "    class_features[labels[i]].append(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 190.,  108.,   43.,   64.,   93.,   18.],\n        [ 108.,  904.,  238.,   60.,   79.,   31.],\n        [  43.,  238., 2082.,  180.,   47.,   67.],\n        [  64.,   60.,  180., 1256.,   50.,   37.],\n        [  93.,   79.,   47.,   50., 1378.,   86.],\n        [  18.,   31.,   67.,   37.,   86.,  892.]])\n"
     ]
    }
   ],
   "source": [
    "edge_distri = torch.zeros(config['n_class'], config['n_class'])\n",
    "for i in range(config['n_edge']):\n",
    "    u = edge_index[0][i]\n",
    "    v = edge_index[1][i]\n",
    "    edge_distri[labels[u], labels[v]] += 1\n",
    "print(edge_distri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_features = torch.zeros(config['n_class'], config['n_feature'])\n",
    "for clas in range(config['n_class']):\n",
    "    for ft in class_features[clas]:\n",
    "        sum_features[clas] += torch.tensor(ft).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1774., 2753., 1592., 2537.,  591., 2508., 2532., 1602., 2584., 2116.,\n         2345., 2708.,  804., 2059., 2534., 2650., 2703., 1223.,  197.,   63.],\n        [1845.,  100., 2532., 2537., 2584.,  591.,  166., 2508.,  717., 2059.,\n         1223., 1943., 1257., 2116., 1602., 1774.,  411., 3173., 2213., 2211.],\n        [3534.,  865., 3429., 2849.,  591., 2719., 2537., 3217., 2708.,  717.,\n          981., 2608., 2586., 2508., 1845., 3560., 2584., 3602., 1602., 2345.],\n        [ 717.,  719., 2608.,  165., 2116., 2270., 2537., 2584.,  591., 2508.,\n         1959., 1590., 2532., 2700., 1602., 2534., 1819., 3124., 2345., 2685.],\n        [  63., 2158., 2537., 1592., 2116.,  165., 1602.,  796.,  591.,  804.,\n          852.,  166.,  174.,   17., 2586., 2978., 2508., 2112.,  244., 2584.],\n        [3429., 1597., 1599.,  796., 2537., 2584., 2508., 2586.,  165., 2708.,\n         1451.,  997.,  793., 1602., 2700.,  804., 3192.,   17., 2116., 1223.]])\n"
     ]
    }
   ],
   "source": [
    "top_clas = torch.zeros(config['n_class'], 20)\n",
    "for i, sum_ft in enumerate(sum_features):\n",
    "    top_clas[i] = sum_ft.sort(descending=True)[1][:20]\n",
    "\n",
    "print(top_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[10.,  5.,  2.,  5.,  5.,  3.],\n        [ 5., 10.,  3.,  5.,  2.,  3.],\n        [ 2.,  3., 10.,  3.,  2.,  3.],\n        [ 5.,  5.,  3., 10.,  4.,  4.],\n        [ 5.,  2.,  2.,  4., 10.,  3.],\n        [ 3.,  3.,  3.,  4.,  3., 10.]])\n"
     ]
    }
   ],
   "source": [
    "def overlap(x, y):\n",
    "    return len(set(x.tolist()).intersection(set(y.tolist())))\n",
    "\n",
    "matrix = torch.zeros(config['n_class'], config['n_class'])\n",
    "for i in range(config['n_class']):\n",
    "    for j in range(config['n_class']):\n",
    "        matrix[i, j] = overlap(top_clas[i], top_clas[j])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}